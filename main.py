import io
import cv2
import numpy as np
from PIL import Image
from fastapi import FastAPI, UploadFile, File, Response, HTTPException, status, Form
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import zipfile # Necesario para crear archivos ZIP

# üöÄ Inicializar FastAPI
app = FastAPI()

# üõ°Ô∏è A√±adir CORS para que tu HTML pueda hacer peticiones sin bloqueo
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://weboluciona.com"], # Puedes restringirlo a tu dominio si prefieres (ej. ["https://tudominio.com"])
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# üé® PARAMETROS CLAVE PARA AJUSTAR LA ELIMINACI√ìN DEL FONDO (Valores por defecto si no se proporcionan)
DEFAULT_LOWER_HSV_H = 140
DEFAULT_LOWER_HSV_S = 50
DEFAULT_LOWER_HSV_V = 50
DEFAULT_UPPER_HSV_H = 170
DEFAULT_UPPER_HSV_S = 255
DEFAULT_UPPER_HSV_V = 255

DEFAULT_FEATHER_BLUR_KERNEL_SIZE = 19
DEFAULT_ALPHA_THRESHOLD_FG = 200
DEFAULT_ALPHA_THRESHOLD_BG = 160
DEFAULT_MORPH_KERNEL_SIZE = 5
DEFAULT_MORPH_ITERATIONS = 3

# --- Funci√≥n de l√≥gica principal de Chroma Key (REUTILIZABLE) ---
# Ahora devuelve la imagen RGBA PROCESADA y la M√ÅSCARA BINARIA para detecci√≥n de contornos
def _apply_chroma_key_logic(
    image_np: np.ndarray, # Espera una imagen OpenCV (BGR)
    lower_hsv_h: int, lower_hsv_s: int, lower_hsv_v: int,
    upper_hsv_h: int, upper_hsv_s: int, upper_hsv_v: int,
    feather_blur_kernel_size: int,
    alpha_threshold_fg: int, alpha_threshold_bg: int,
    morph_kernel_size: int, morph_iterations: int
) -> tuple[np.ndarray, np.ndarray]: # Devuelve (imagen RGBA, m√°scara binaria para contornos)
    """
    Aplica el algoritmo de Chroma Key avanzado a una imagen y devuelve la imagen RGBA
    y una m√°scara binaria limpia para la detecci√≥n de contornos.
    """
    # 1. Definir los l√≠mites HSV
    lower_hsv = np.array([lower_hsv_h, lower_hsv_s, lower_hsv_v])
    upper_hsv = np.array([upper_hsv_h, upper_hsv_s, upper_hsv_v])

    hsv_image = cv2.cvtColor(image_np, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv_image, lower_hsv, upper_hsv)
    mask_inverted = cv2.bitwise_not(mask) # M√°scara del objeto (p√∫a)

    # 2. Desenfoque y canal alfa
    if feather_blur_kernel_size % 2 == 0 or feather_blur_kernel_size <= 0:
        feather_blur_kernel_size = 15 if feather_blur_kernel_size <= 0 else feather_blur_kernel_size + 1
    feather_blur_kernel_tuple = (feather_blur_kernel_size, feather_blur_kernel_size)
    blurred_mask = cv2.GaussianBlur(mask_inverted, feather_blur_kernel_tuple, 0)
    
    alpha_channel = np.interp(blurred_mask,
                              [alpha_threshold_bg, alpha_threshold_fg],
                              [0, 255]).astype(np.uint8)

    # 3. Combinar con la imagen original para obtener la imagen RGBA final
    b, g, r = cv2.split(image_np)
    rgba_image = cv2.merge([b, g, r, alpha_channel])

    # 4. Crear una m√°scara binaria limpia para encontrar contornos (usando el alpha_channel)
    # Aplicamos umbral y operaciones morfol√≥gicas para asegurar contornos bien definidos
    binary_mask_for_contours = alpha_channel.copy()
    _, binary_mask_for_contours = cv2.threshold(binary_mask_for_contours, 1, 255, cv2.THRESH_BINARY)
    
    # Operaciones morfol√≥gicas para limpiar y separar contornos antes de findContours
    if morph_kernel_size % 2 == 0 or morph_kernel_size <= 0:
        morph_kernel_size = 5 if morph_kernel_size <=0 else morph_kernel_size + 1
    kernel_morph_batch = np.ones((morph_kernel_size, morph_kernel_size), np.uint8) 
    
    binary_mask_for_contours = cv2.morphologyEx(binary_mask_for_contours, cv2.MORPH_CLOSE, kernel_morph_batch, iterations=morph_iterations)
    binary_mask_for_contours = cv2.morphologyEx(binary_mask_for_contours, cv2.MORPH_OPEN, kernel_morph_batch, iterations=morph_iterations)

    return rgba_image, binary_mask_for_contours

# üì∏ Endpoint de salud para Render
@app.get("/healthz", summary="Health Check")
def health_check():
    """
    Endpoint para que Render y otros sistemas verifiquen el estado del servicio.
    """
    return {"status": "ok"}

# üè† Endpoint base por si visitas la ra√≠z en el navegador
@app.get("/", summary="Root Endpoint")
def home():
    """
    Endpoint de bienvenida para el servicio de recorte de fondo.
    """
    return {"status": "‚úÖ Servidor de recorte de fondo activo (m√©todo chroma key avanzado)"}

# üì∏ Endpoint para procesar una sola imagen y quitar el fondo
@app.post("/procesar-foto", summary="Process single image and remove background with provided parameters")
async def procesar_foto(
    file: UploadFile = File(...),
    lower_hsv_h: int | None = Form(DEFAULT_LOWER_HSV_H),
    lower_hsv_s: int | None = Form(DEFAULT_LOWER_HSV_S),
    lower_hsv_v: int | None = Form(DEFAULT_LOWER_HSV_V),
    upper_hsv_h: int | None = Form(DEFAULT_UPPER_HSV_H),
    upper_hsv_s: int | None = Form(DEFAULT_UPPER_HSV_S),
    upper_hsv_v: int | None = Form(DEFAULT_UPPER_HSV_V),
    feather_blur_kernel_size: int | None = Form(DEFAULT_FEATHER_BLUR_KERNEL_SIZE),
    alpha_threshold_fg: int | None = Form(DEFAULT_ALPHA_THRESHOLD_FG),
    alpha_threshold_bg: int | None = Form(DEFAULT_ALPHA_THRESHOLD_BG),
    morph_kernel_size: int | None = Form(DEFAULT_MORPH_KERNEL_SIZE),
    morph_iterations: int | None = Form(DEFAULT_MORPH_ITERATIONS)
):
    """
    Recibe una imagen y TODOS los par√°metros de configuraci√≥n para chroma key desde el frontend/PHP,
    aplica el algoritmo, redimensiona a un m√°ximo de 350px de ancho y devuelve la imagen con el fondo eliminado (WebP con transparencia).
    """
    try:
        input_bytes = await file.read()
        pil_image = Image.open(io.BytesIO(input_bytes)).convert("RGB")
        opencv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

        # Aplicar la l√≥gica de Chroma Key (solo necesitamos la imagen RGBA aqu√≠)
        rgba_image, _ = _apply_chroma_key_logic( # Ignoramos la m√°scara binaria
            opencv_image,
            lower_hsv_h, lower_hsv_s, lower_hsv_v,
            upper_hsv_h, upper_hsv_s, upper_hsv_v,
            feather_blur_kernel_size,
            alpha_threshold_fg, alpha_threshold_bg,
            morph_kernel_size, morph_iterations
        )

        # Convertir a PIL Image para redimensionar y guardar como WebP
        output_pil_image = Image.fromarray(cv2.cvtColor(rgba_image, cv2.COLOR_BGR2RGBA))
        
        # --- Redimensionar la imagen si su ancho es mayor a 350px ---
        MAX_WIDTH_OUTPUT = 350
        if output_pil_image.width > MAX_WIDTH_OUTPUT:
            aspect_ratio = output_pil_image.height / output_pil_image.width
            new_height = int(MAX_WIDTH_OUTPUT * aspect_ratio)
            output_pil_image = output_pil_image.resize((MAX_WIDTH_OUTPUT, new_height), Image.LANCZOS)

        # Guardar en buffer como WebP
        output_buffer = io.BytesIO()
        output_pil_image.save(output_buffer, format="WEBP", quality=80, method=6) # method=6 para mejor compresi√≥n WebP
        output_buffer.seek(0)
        
        return Response(content=output_buffer.getvalue(), media_type="image/webp")

    except HTTPException: # Re-lanza HTTPExceptions ya definidas (ej. 400 Bad Request)
        raise
    except Exception as e:
        print(f"ERROR: Fallo al procesar la foto (chroma key OpenCV): {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Error processing image: {e}")

# --- NUEVA RUTA: Procesamiento por Lotes ---
@app.post("/batch-process", summary="Process A4 image with multiple picks and return a ZIP of cropped WebP images")
async def batch_process(
    file: UploadFile = File(...),
    lower_hsv_h: int | None = Form(DEFAULT_LOWER_HSV_H),
    lower_hsv_s: int | None = Form(DEFAULT_LOWER_HSV_S),
    lower_hsv_v: int | None = Form(DEFAULT_LOWER_HSV_V),
    upper_hsv_h: int | None = Form(DEFAULT_UPPER_HSV_H),
    upper_hsv_s: int | None = Form(DEFAULT_UPPER_HSV_S),
    upper_hsv_v: int | None = Form(DEFAULT_UPPER_HSV_V),
    feather_blur_kernel_size: int | None = Form(DEFAULT_FEATHER_BLUR_KERNEL_SIZE),
    alpha_threshold_fg: int | None = Form(DEFAULT_ALPHA_THRESHOLD_FG),
    alpha_threshold_bg: int | None = Form(DEFAULT_ALPHA_THRESHOLD_BG),
    morph_kernel_size: int | None = Form(DEFAULT_MORPH_KERNEL_SIZE),
    morph_iterations: int | None = Form(DEFAULT_MORPH_ITERATIONS),
    file_prefix: str = Form("pua") # Recibe el prefijo del frontend
):
    """
    Recibe una imagen A4 con m√∫ltiples p√∫as en un fondo chroma,
    elimina el fondo, detecta cada p√∫a, la rota para que quede vertical
    y devuelve un archivo ZIP con cada p√∫a recortada como un archivo WebP individual.
    """
    try:
        # Leer la imagen A4
        contents = await file.read()
        nparr = np.frombuffer(contents, np.uint8)
        img_a4 = cv2.imdecode(nparr, cv2.IMREAD_COLOR) # Lee como BGR

        if img_a4 is None:
            raise HTTPException(status_code=400, detail="No se pudo decodificar la imagen A4.")

        # 1. Aplicar Chroma Key a toda la imagen A4
        # Ahora _apply_chroma_key_logic devuelve la imagen RGBA y la m√°scara binaria
        processed_a4_img_rgba, binary_mask_for_contours = _apply_chroma_key_logic(
            img_a4,
            lower_hsv_h, lower_hsv_s, lower_hsv_v,
            upper_hsv_h, upper_hsv_s, upper_hsv_v,
            feather_blur_kernel_size,
            alpha_threshold_fg, alpha_threshold_bg,
            morph_kernel_size, morph_iterations
        )

        # 2. Detecci√≥n de Contornos (para identificar cada p√∫a)
        contours, _ = cv2.findContours(binary_mask_for_contours, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # --- A√ëADIR ESTOS PRINTS TEMPORALES PARA DEPURACI√ìN ---
        print("\n--- INICIO DE DEBUG: √Åreas de Contornos Detectados ---")
        if not contours:
            print("No se detectaron contornos en la imagen A4. Intenta ajustar los par√°metros HSV o los par√°metros morfol√≥gicos.")
        # --- FIN DE PRINTS TEMPORALES ---

        output_images = []
        MIN_PUA_AREA = 12000  # √Årea m√≠nima para considerar un contorno como una p√∫a
        MAX_PUA_AREA = 30000  # √Årea m√°xima para evitar detectar la hoja completa

        for i, contour in enumerate(contours):
            area = cv2.contourArea(contour)
            print(f"Contorno {i+1}: √Årea = {int(area)} p√≠xeles cuadrados") # Debugging
            
            if MIN_PUA_AREA < area < MAX_PUA_AREA: 
                # Obtener el rect√°ngulo de √°rea m√≠nima y su √°ngulo
                rect = cv2.minAreaRect(contour)
                (center_x, center_y), (width, height), angle = rect

                # --- L√≥gica de Rotaci√≥n para Verticalidad ---
                # Ajustar el √°ngulo para que el lado m√°s largo sea la "altura"
                if width < height: # Si el 'height' es el lado m√°s largo
                    # El √°ngulo ya est√° referenciado al eje Y (vertical)
                    # minAreaRect da √°ngulos en [-90, 0) para rect√°ngulos m√°s altos que anchos.
                    # Queremos que la p√∫a quede con 0 grados (vertical)
                    rotation_angle = angle
                else: # Si el 'width' es el lado m√°s largo (rect√°ngulo "acostado")
                    # El √°ngulo est√° referenciado al eje X (horizontal)
                    # Sumamos 90 para referenciarlo al eje Y (vertical)
                    rotation_angle = angle + 90
                
                # Para asegurar que la p√∫a no quede "boca abajo"
                # Esto es una heur√≠stica y puede requerir ajuste fino si las p√∫as tienen una orientaci√≥n preferida
                # (ej. la punta siempre hacia abajo).
                # Por ahora, simplemente rota para que el lado m√°s largo sea vertical.
                
                # Crear la matriz de rotaci√≥n
                M = cv2.getRotationMatrix2D((center_x, center_y), rotation_angle, 1.0)
                
                # Calcular las nuevas dimensiones de la imagen despu√©s de rotar para evitar recortes
                cos = np.abs(M[0, 0])
                sin = np.abs(M[0, 1])
                new_width = int((processed_a4_img_rgba.shape[1] * cos) + (processed_a4_img_rgba.shape[0] * sin))
                new_height = int((processed_a4_img_rgba.shape[1] * sin) + (processed_a4_img_rgba.shape[0] * cos))

                # Ajustar la matriz de rotaci√≥n para trasladar la imagen al nuevo centro
                M[0, 2] += (new_width / 2) - center_x
                M[1, 2] += (new_height / 2) - center_y

                # Rotar la imagen RGBA completa
                rotated_image_full = cv2.warpAffine(processed_a4_img_rgba, M, (new_width, new_height), 
                                                    flags=cv2.INTER_LANCZOS4, 
                                                    borderMode=cv2.BORDER_CONSTANT, 
                                                    borderValue=(0, 0, 0, 0)) # Fondo transparente

                # Transformar el contorno original con la misma matriz de rotaci√≥n
                # Esto nos da la nueva posici√≥n del contorno en la imagen rotada
                transformed_contour = cv2.transform(contour.reshape(-1, 1, 2), M).reshape(-1, 1, 2)
                
                # Obtener el nuevo rect√°ngulo delimitador (axial) de la p√∫a en la imagen rotada
                x_rot, y_rot, w_rot, h_rot = cv2.boundingRect(transformed_contour)

                # A√±adir un peque√±o padding al recorte final
                padding = 10 
                x_final = max(0, x_rot - padding)
                y_final = max(0, y_rot - padding)
                w_final = min(rotated_image_full.shape[1] - x_final, w_rot + 2 * padding)
                h_final = min(rotated_image_full.shape[0] - y_final, h_rot + 2 * padding)
                
                # Recortar la p√∫a de la imagen rotada completa
                pua_cropped_rgba = rotated_image_full[y_final : y_final + h_final, x_final : x_final + w_final]

                if pua_cropped_rgba.size == 0:
                    print(f"Advertencia: Recorte vac√≠o para contorno {i+1}. Saltando.")
                    continue 

                # Convertir a WebP y a√±adir a la lista de salida
                is_success, buffer = cv2.imencode(".webp", pua_cropped_rgba)
                if is_success:
                    output_images.append({
                        "filename": f"{file_prefix}_{i+1}.webp", # Usamos el prefijo aqu√≠
                        "data": io.BytesIO(buffer.tobytes())
                    })
        
        if not output_images:
            raise HTTPException(status_code=404, detail=f"No se detectaron p√∫as v√°lidas para procesar con los par√°metros dados. Verifique el rango de √°rea ({MIN_PUA_AREA}-{MAX_PUA_AREA}) o los par√°metros de Chroma Key.")

        # 3. Comprimir todas las im√°genes en un archivo ZIP
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
            for img_info in output_images:
                zf.writestr(img_info["filename"], img_info["data"].getvalue())
        zip_buffer.seek(0)
        
        # Define el nombre del archivo ZIP
        zip_filename = f"{file_prefix}_puas_procesadas.zip"

        return StreamingResponse(
            zip_buffer,
            media_type="application/zip",
            headers={"Content-Disposition": f"attachment; filename={zip_filename}"}
        )

    except HTTPException: # Re-lanza HTTPExceptions ya definidas
        raise
    except Exception as e:
        print(f"ERROR en batch-process: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Error interno del servidor al procesar por lotes: {e}")
